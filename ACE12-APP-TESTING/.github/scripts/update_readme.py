import os
import sys
from openai import OpenAI
from pathlib import Path
from dotenv import load_dotenv

# Cargar variables de entorno desde .env
load_dotenv()

def inicializar_cliente():
    """Configura el cliente de OpenAI con la clave API"""
    clave_api = os.getenv("OPENAI_API_KEY")
    if not clave_api:
        print("‚ùå Error: No se encontr√≥ la variable de entorno OPENAI_API_KEY", file=sys.stderr)
        sys.exit(1)
    return OpenAI(api_key=clave_api)

def generar_documentacion_esql_individual(cliente, archivo_esql):
    """Genera documentaci√≥n individual para un archivo .esql espec√≠fico"""
    try:
        with open(archivo_esql, 'r', encoding='utf-8') as f:
            contenido_esql = f.read()
        
        prompt_sistema = """Eres un experto en Elasticsearch y ES|QL. Tu tarea es analizar c√≥digo ES|QL y crear documentaci√≥n t√©cnica clara y detallada.

INSTRUCCIONES:
1. Analiza el c√≥digo ES|QL proporcionado
2. Crea un documento .md en espa√±ol que incluya:
   - T√≠tulo descriptivo del archivo
   - Prop√≥sito y objetivo de la consulta
   - Explicaci√≥n paso a paso de lo que hace el c√≥digo
   - Campos/√≠ndices que utiliza
   - Filtros y transformaciones aplicadas
   - Resultado esperado
   - Casos de uso
   - Notas t√©cnicas importantes

3. Usa markdown correctamente con:
   - Encabezados apropiados
   - Bloques de c√≥digo con syntax highlighting
   - Listas cuando sea necesario
   - Tablas si es apropiado
   - Emojis para mejorar la legibilidad

4. S√© t√©cnico pero accesible
5. Si encuentras comandos espec√≠ficos de ES|QL, expl√≠calos

FORMATO: Responde SOLO con el contenido del archivo .md, sin explicaciones adicionales."""

        respuesta = cliente.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": prompt_sistema},
                {"role": "user", "content": f"Analiza este archivo ES|QL y crea su documentaci√≥n:\n\nNOMBRE DEL ARCHIVO: {archivo_esql.name}\nRUTA: {archivo_esql}\n\nC√ìDIGO ES|QL:\n```esql\n{contenido_esql}\n```"}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        
        contenido_md = respuesta.choices[0].message.content
        tokens_usados = respuesta.usage.total_tokens
        
        return contenido_md, tokens_usados
        
    except Exception as e:
        print(f"‚ùå Error al generar documentaci√≥n para {archivo_esql.name}: {str(e)}", file=sys.stderr)
        return None, 0

def procesar_archivos_esql_individuales(cliente):
    """Procesa cada archivo .esql y genera su documentaci√≥n individual"""
    archivos_esql = list(Path('.').rglob('*.esql'))
    
    if not archivos_esql:
        print("üìù No se encontraron archivos .esql para documentar individualmente")
        return [], 0
    
    archivos_documentados = []
    total_tokens = 0
    
    print(f"üìÑ Encontrados {len(archivos_esql)} archivo(s) .esql para documentar...")
    
    for archivo in archivos_esql:
        print(f"üîç Procesando {archivo.name}...")
        
        # Generar documentaci√≥n
        documentacion, tokens = generar_documentacion_esql_individual(cliente, archivo)
        
        if documentacion:
            # Crear archivo .md con el mismo nombre
            nombre_md = archivo.stem + '.md'  # Cambia .esql por .md
            ruta_md = archivo.parent / nombre_md
            
            try:
                with open(ruta_md, 'w', encoding='utf-8') as f:
                    f.write(documentacion)
                
                print(f"‚úÖ Documentaci√≥n creada: {ruta_md}")
                archivos_documentados.append({
                    'esql': archivo,
                    'md': ruta_md,
                    'tokens': tokens
                })
                total_tokens += tokens
                
            except Exception as e:
                print(f"‚ùå Error al escribir {nombre_md}: {str(e)}")
        
        else:
            print(f"‚ùå No se pudo generar documentaci√≥n para {archivo.name}")
    
    return archivos_documentados, total_tokens

def analizar_archivos_esql():
    """Analiza los archivos .esql en el proyecto y devuelve el an√°lisis y el conteo."""
    archivos_esql = list(Path('.').rglob('*.esql'))
    
    if not archivos_esql:
        return "No se encontraron archivos .esql\n", 0
    
    # Limitar archivos a procesar para el README general
    archivos_a_procesar = archivos_esql[:5]  # Increment√© a 5 para mejor visi√≥n general
    
    analisis = "## üìä An√°lisis de archivos ES|QL\n\n"
    analisis += f"**Total de archivos encontrados:** {len(archivos_esql)}\n\n"
    
    for archivo in archivos_a_procesar:
        try:
            with open(archivo, 'r', encoding='utf-8') as f:
                contenido = f.read()
                analisis += f"### üìÑ {archivo.name}\n"
                analisis += f"**Ruta:** `{archivo}`\n"
                analisis += f"**Tama√±o:** {len(contenido)} caracteres\n"
                
                # Mostrar solo las primeras l√≠neas para el README general
                lineas = contenido.split('\n')[:8]
                contenido_muestra = '\n'.join(lineas)
                analisis += f"```esql\n{contenido_muestra}\n```\n"
                
                # Mencionar que existe documentaci√≥n individual
                nombre_md = archivo.stem + '.md'
                analisis += f"üìñ **Documentaci√≥n detallada:** `{nombre_md}`\n\n"
                
        except Exception as e:
            analisis += f"\n‚ùå Error leyendo {archivo.name}: {str(e)}\n"
    
    if len(archivos_esql) > len(archivos_a_procesar):
        analisis += f"*... y {len(archivos_esql) - len(archivos_a_procesar)} archivo(s) m√°s*\n\n"
    
    return analisis, len(archivos_esql)

def analizar_archivos_py():
    """Analiza los archivos .py en el proyecto y devuelve el an√°lisis y el conteo."""
    archivos_py = list(Path('.').rglob('*.py'))
    archivos_py = [f for f in archivos_py if not f.parts[0].startswith(('.', 'venv', '__pycache__'))]
    
    if not archivos_py:
        return "No se encontraron archivos .py\n", 0
        
    # Limitar archivos a procesar
    archivos_a_procesar = archivos_py[:3]
    
    analisis = "## üêç An√°lisis de archivos Python\n\n"
    analisis += f"**Total de archivos encontrados:** {len(archivos_py)}\n\n"
    
    for archivo in archivos_a_procesar:
        try:
            with open(archivo, 'r', encoding='utf-8') as f:
                contenido = f.read(1500)
                analisis += f"### üìÑ {archivo.name}\n"
                analisis += f"**Ruta:** `{archivo}`\n"
                
                docstring = extraer_docstring(contenido)
                if docstring:
                    analisis += f"**Descripci√≥n:** {docstring}\n"
                
                analisis += f"```python\n{contenido[:400]}...\n```\n\n"
        except Exception as e:
            analisis += f"\n‚ùå Error leyendo {archivo.name}: {str(e)}\n"
    
    return analisis, len(archivos_py)

def extraer_docstring(codigo):
    """Extrae la docstring de un archivo Python"""
    lines = codigo.split('\n')
    for line in lines[:10]:
        if '"""' in line or "'''" in line:
            return line.replace('"""', '').replace("'''", '').strip()
    return None

def generar_readme(cliente, analisis_esql, analisis_py, archivos_documentados):
    """Genera el README principal usando OpenAI"""
    try:
        # Crear lista de archivos documentados para incluir en el README
        lista_documentacion = ""
        if archivos_documentados:
            lista_documentacion = "\n## üìö Documentaci√≥n Individual de Archivos ES|QL\n\n"
            lista_documentacion += "Cada archivo `.esql` tiene su propia documentaci√≥n detallada:\n\n"
            for doc in archivos_documentados:
                lista_documentacion += f"- [`{doc['esql'].name}`]({doc['md'].name}) - Documentaci√≥n detallada del archivo ES|QL\n"
            lista_documentacion += "\n"

        prompt_sistema = """Eres un experto en documentaci√≥n t√©cnica. Tu tarea es crear un README.md profesional y completo bas√°ndose en el an√°lisis de c√≥digo proporcionado.

INSTRUCCIONES:
1. Crea un README.md en espa√±ol que sea informativo y profesional
2. Incluye las siguientes secciones:
   - T√≠tulo del proyecto (ded√∫celo del c√≥digo)
   - Descripci√≥n breve y clara
   - üéØ Caracter√≠sticas principales
   - üìÅ Estructura del proyecto
   - üöÄ Instalaci√≥n
   - üìñ Uso
   - üìä Archivos ES|QL (si los hay)
   - üêç Scripts Python (si los hay)
   - üìö Documentaci√≥n
   - ü§ù Contribuci√≥n

3. Usa markdown correctamente con encabezados, listas, c√≥digo, etc.
4. Incluye emojis para hacer el README m√°s atractivo
5. S√© descriptivo pero conciso
6. Si hay archivos .esql, explica que es un proyecto relacionado con Elasticsearch/ES|QL
7. Si hay archivos .py, explica la funcionalidad de Python
8. Incluye badges apropiados
9. Menciona la documentaci√≥n individual generada autom√°ticamente

FORMATO: Responde SOLO con el contenido del README.md, sin explicaciones adicionales."""

        contenido_completo = f"{analisis_esql}\n{analisis_py}\n{lista_documentacion}"

        respuesta = cliente.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": prompt_sistema},
                {"role": "user", "content": contenido_completo}
            ],
            temperature=0.3,
            max_tokens=4000
        )
        
        contenido_readme = respuesta.choices[0].message.content
        tokens_prompt = respuesta.usage.prompt_tokens
        tokens_respuesta = respuesta.usage.completion_tokens
        
        return contenido_readme, tokens_prompt, tokens_respuesta
        
    except Exception as e:
        print(f"‚ùå Error al generar README: {str(e)}", file=sys.stderr)
        sys.exit(1)

def main():
    print("üöÄ Iniciando generaci√≥n autom√°tica de documentaci√≥n")
    cliente = inicializar_cliente()
    
    # Paso 1: Generar documentaci√≥n individual para archivos .esql
    print("\n" + "="*60)
    print("üìÑ GENERANDO DOCUMENTACI√ìN INDIVIDUAL PARA ARCHIVOS .ESQL")
    print("="*60)
    archivos_documentados, tokens_individuales = procesar_archivos_esql_individuales(cliente)
    
    # Paso 2: Analizar archivos para el README general
    print("\n" + "="*60)
    print("üìä ANALIZANDO ARCHIVOS PARA README GENERAL")
    print("="*60)
    print("üîç Analizando archivos .esql y .py...")
    analisis_esql, esql_total = analizar_archivos_esql()
    analisis_py, py_total = analizar_archivos_py()
    
    # Paso 3: Generar README principal
    print("ü§ñ Generando README principal con OpenAI...")
    nuevo_readme, tokens_entrada, tokens_salida = generar_readme(cliente, analisis_esql, analisis_py, archivos_documentados)
    
    with open("README.md", "w", encoding='utf-8') as archivo:
        archivo.write(nuevo_readme)
    
    print("‚úÖ README.md generado exitosamente")
    
    # Resumen final
    print("\n" + "="*60)
    print("üìä RESUMEN COMPLETO DE LA EJECUCI√ìN".center(60))
    print("="*60)
    
    print(f"\nüìÑ **Archivos Procesados:**")
    print(f"   - Archivos .esql encontrados: {esql_total}")
    print(f"   - Archivos .py encontrados: {py_total}")
    print(f"   - Documentos .md generados: {len(archivos_documentados)}")
    print(f"   - **Total de archivos analizados:** {esql_total + py_total}")
    
    print(f"\nüìà **Uso de Tokens (API OpenAI):**")
    print(f"   - Tokens para documentaci√≥n individual: {tokens_individuales}")
    print(f"   - Tokens para README (entrada): {tokens_entrada}")
    print(f"   - Tokens para README (respuesta): {tokens_salida}")
    print(f"   - **Total de tokens utilizados:** {tokens_individuales + tokens_entrada + tokens_salida}")
    
    if archivos_documentados:
        print(f"\nüìö **Archivos de Documentaci√≥n Creados:**")
        for doc in archivos_documentados:
            print(f"   - {doc['md'].name} ({doc['tokens']} tokens)")
    
    print("\n" + "="*60)
    print("‚ú® PROCESO COMPLETADO EXITOSAMENTE ‚ú®".center(60))
    print("="*60)

if __name__ == "__main__":
    main()